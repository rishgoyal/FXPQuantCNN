{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating effect of input scaling on shape of weights\n",
    "\n",
    "The objective here is to understand whether scaling the inputs will change the value of the weights. Concretely, if a network is trained on input data that is scaled to [0, 1], then we would like to know whether the network's weights are also scaled inversely if we scale the data further down by an order of magnitude or further up by an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.datasets import mnist, cifar10\n",
    "import sys\n",
    "sys.path.append('C:/Users/320060820/experiments/')\n",
    "import os\n",
    "from quantize import FixedPointQuantizer\n",
    "import quantize\n",
    "from train_model import convert_data\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to restart layer numbering\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../../test_models/'\n",
    "model_path = 'cifar_keras/cifar_keras.h5'\n",
    "num_classes = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model(save_path + model_path)\n",
    "model1_param = quantize.get_model_weights(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 2550.\n",
    "x_test /= 2550.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "model2.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "model2.add(layers.GlobalMaxPooling2D())\n",
    "model2.add(layers.Dropout(0.25))\n",
    "model2.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 3.3977 - acc: 0.1988 - val_loss: 1.8404 - val_acc: 0.3381\n",
      "Epoch 2/70\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 2.1670 - acc: 0.2669 - val_loss: 1.6746 - val_acc: 0.4110\n",
      "Epoch 3/70\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 1.9226 - acc: 0.3214 - val_loss: 1.5599 - val_acc: 0.4575\n",
      "Epoch 4/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.7686 - acc: 0.3678 - val_loss: 1.4771 - val_acc: 0.4881\n",
      "Epoch 5/70\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.6554 - acc: 0.4055 - val_loss: 1.4248 - val_acc: 0.5134\n",
      "Epoch 6/70\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.5743 - acc: 0.4320 - val_loss: 1.3717 - val_acc: 0.5260\n",
      "Epoch 7/70\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 1.4994 - acc: 0.4627 - val_loss: 1.3427 - val_acc: 0.5365\n",
      "Epoch 8/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.4494 - acc: 0.4820 - val_loss: 1.3167 - val_acc: 0.5434\n",
      "Epoch 9/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.3928 - acc: 0.5033 - val_loss: 1.2436 - val_acc: 0.5728\n",
      "Epoch 10/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.3587 - acc: 0.5151 - val_loss: 1.2069 - val_acc: 0.5814\n",
      "Epoch 11/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.3221 - acc: 0.5288 - val_loss: 1.2369 - val_acc: 0.5632\n",
      "Epoch 12/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.2880 - acc: 0.5437 - val_loss: 1.1552 - val_acc: 0.6077\n",
      "Epoch 13/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.2568 - acc: 0.5537 - val_loss: 1.1747 - val_acc: 0.5970\n",
      "Epoch 14/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.2350 - acc: 0.5635 - val_loss: 1.2289 - val_acc: 0.5562\n",
      "Epoch 15/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.2107 - acc: 0.5698 - val_loss: 1.1246 - val_acc: 0.6059\n",
      "Epoch 16/70\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 1.1946 - acc: 0.5786 - val_loss: 1.0949 - val_acc: 0.6295\n",
      "Epoch 17/70\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.1784 - acc: 0.5808 - val_loss: 1.1022 - val_acc: 0.6138\n",
      "Epoch 18/70\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 1.1558 - acc: 0.5891 - val_loss: 1.0715 - val_acc: 0.6261\n",
      "Epoch 19/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.1361 - acc: 0.5996 - val_loss: 1.1351 - val_acc: 0.5874\n",
      "Epoch 20/70\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.1258 - acc: 0.6008 - val_loss: 1.0544 - val_acc: 0.6310\n",
      "Epoch 21/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.1118 - acc: 0.6092 - val_loss: 1.0616 - val_acc: 0.6281\n",
      "Epoch 22/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.0976 - acc: 0.6111 - val_loss: 1.0324 - val_acc: 0.6489\n",
      "Epoch 23/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.0836 - acc: 0.6180 - val_loss: 0.9736 - val_acc: 0.6615\n",
      "Epoch 24/70\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 1.0724 - acc: 0.6230 - val_loss: 1.0682 - val_acc: 0.6119\n",
      "Epoch 25/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.0671 - acc: 0.6240 - val_loss: 1.0927 - val_acc: 0.6020\n",
      "Epoch 26/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.0504 - acc: 0.6287 - val_loss: 0.9768 - val_acc: 0.6604\n",
      "Epoch 27/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.0462 - acc: 0.6321 - val_loss: 0.9623 - val_acc: 0.669460 - acc\n",
      "Epoch 28/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.0331 - acc: 0.6365 - val_loss: 0.9795 - val_acc: 0.6468\n",
      "Epoch 29/70\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.0235 - acc: 0.6395 - val_loss: 0.9564 - val_acc: 0.6712\n",
      "Epoch 30/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.0188 - acc: 0.6410 - val_loss: 0.9517 - val_acc: 0.6784\n",
      "Epoch 31/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.0115 - acc: 0.6440 - val_loss: 0.9445 - val_acc: 0.6704\n",
      "Epoch 32/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.9995 - acc: 0.6484 - val_loss: 0.9320 - val_acc: 0.6770\n",
      "Epoch 33/70\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.9930 - acc: 0.6512 - val_loss: 0.9602 - val_acc: 0.6699\n",
      "Epoch 34/70\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 0.9856 - acc: 0.6530 - val_loss: 0.9054 - val_acc: 0.6864\n",
      "Epoch 35/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.9813 - acc: 0.6566 - val_loss: 0.9468 - val_acc: 0.6645\n",
      "Epoch 36/70\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.9788 - acc: 0.6560 - val_loss: 0.9761 - val_acc: 0.6569\n",
      "Epoch 37/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.9678 - acc: 0.6629 - val_loss: 0.9734 - val_acc: 0.6576\n",
      "Epoch 38/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.9579 - acc: 0.6665 - val_loss: 0.9165 - val_acc: 0.6773\n",
      "Epoch 39/70\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.9523 - acc: 0.6657 - val_loss: 0.9114 - val_acc: 0.6784\n",
      "Epoch 40/70\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.9426 - acc: 0.6698 - val_loss: 0.8658 - val_acc: 0.6965\n",
      "Epoch 41/70\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.9408 - acc: 0.6702 - val_loss: 0.8584 - val_acc: 0.7041\n",
      "Epoch 42/70\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.9391 - acc: 0.6689 - val_loss: 0.9236 - val_acc: 0.6707\n",
      "Epoch 43/70\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.9327 - acc: 0.6725 - val_loss: 0.9011 - val_acc: 0.6796\n",
      "Epoch 44/70\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.9284 - acc: 0.6740 - val_loss: 0.8364 - val_acc: 0.7112\n",
      "Epoch 45/70\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.9190 - acc: 0.6771 - val_loss: 0.8617 - val_acc: 0.6988\n",
      "Epoch 46/70\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.9144 - acc: 0.6792 - val_loss: 1.1960 - val_acc: 0.57938 - ETA: 1s - loss: 0.9161 -  - ETA: 0s - loss: 0.9147\n",
      "Epoch 47/70\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.9100 - acc: 0.6808 - val_loss: 0.9399 - val_acc: 0.6676\n",
      "Epoch 48/70\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.9114 - acc: 0.6805 - val_loss: 0.8286 - val_acc: 0.7120\n",
      "Epoch 49/70\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.9015 - acc: 0.6819 - val_loss: 0.8824 - val_acc: 0.6847\n",
      "Epoch 50/70\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8969 - acc: 0.6890 - val_loss: 0.9456 - val_acc: 0.6648\n",
      "Epoch 51/70\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.8926 - acc: 0.6893 - val_loss: 0.9592 - val_acc: 0.6606\n",
      "Epoch 52/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.8933 - acc: 0.6879 - val_loss: 0.8815 - val_acc: 0.6951\n",
      "Epoch 53/70\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.8801 - acc: 0.6914 - val_loss: 0.9663 - val_acc: 0.6628\n",
      "Epoch 54/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.8823 - acc: 0.6933 - val_loss: 0.9034 - val_acc: 0.6729\n",
      "Epoch 55/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.8741 - acc: 0.6940 - val_loss: 0.8277 - val_acc: 0.7093\n",
      "Epoch 56/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.8719 - acc: 0.6955 - val_loss: 0.8127 - val_acc: 0.7157\n",
      "Epoch 57/70\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.8755 - acc: 0.6943 - val_loss: 0.8198 - val_acc: 0.7128\n",
      "Epoch 58/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.8655 - acc: 0.6972 - val_loss: 0.8813 - val_acc: 0.6909\n",
      "Epoch 59/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.8627 - acc: 0.6998 - val_loss: 0.8805 - val_acc: 0.6884\n",
      "Epoch 60/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.8582 - acc: 0.6990 - val_loss: 0.8267 - val_acc: 0.7084\n",
      "Epoch 61/70\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8531 - acc: 0.7023 - val_loss: 0.8587 - val_acc: 0.6937\n",
      "Epoch 62/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.8560 - acc: 0.6990 - val_loss: 0.8005 - val_acc: 0.7187\n",
      "Epoch 63/70\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.8567 - acc: 0.6987 - val_loss: 0.8995 - val_acc: 0.6793\n",
      "Epoch 64/70\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.8444 - acc: 0.7040 - val_loss: 0.8532 - val_acc: 0.7010\n",
      "Epoch 65/70\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.8489 - acc: 0.7040 - val_loss: 0.8430 - val_acc: 0.7029\n",
      "Epoch 66/70\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8413 - acc: 0.7028 - val_loss: 0.7626 - val_acc: 0.7347\n",
      "Epoch 67/70\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.8411 - acc: 0.7059 - val_loss: 0.8201 - val_acc: 0.7049\n",
      "Epoch 68/70\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8354 - acc: 0.7077 - val_loss: 0.8975 - val_acc: 0.6895\n",
      "Epoch 69/70\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.8380 - acc: 0.7076 - val_loss: 0.8494 - val_acc: 0.7004\n",
      "Epoch 70/70\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 0.8312 - acc: 0.7094 - val_loss: 0.9526 - val_acc: 0.6648\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(x_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEitJREFUeJzt3X+M5HV9x/HnWw6wqQgHLJTcgUvD1R52LdjtSUusLSgc2ng0kRSjcppr7g9pY2NtXWsTWiiJP1IxxGo8hbiYVkCqcvFAXA+oaSI/jkIP4aq3ooXtXbizB7SESIu++8d8FoZj92Z2d/Y7s/t5PpLJfL+f7+c78/7c7M1r5vtrIjORJNXnZf0uQJLUHwaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqlRXARARP46IByPigYjYUdqOjYiJiNhd7leW9oiIqyNiMiJ2RsTr2h5nY+m/OyI2Ls6QJEndmMs3gN/LzDMyc7TMjwHbM3MNsL3MA1wArCm3zcBnoRUYwGXA64F1wGXToSFJat6KBay7AfjdMj0O3Al8qLRfl61TjO+KiGMi4qTSdyIzDwBExASwHvjybE9w/PHH5/Dw8AJKlKT63HfffT/JzKFO/boNgAS+FREJfC4ztwAnZuZegMzcGxEnlL6rgMfa1p0qbbO1z2p4eJgdO3Z0WaIkCSAi/qObft0GwNmZuae8yU9ExL8f6rlnaMtDtL945YjNtDYdccopp3RZniRprrraB5CZe8r9PuBrtLbhP1427VDu95XuU8DJbauvBvYcov3g59qSmaOZOTo01PEbjCRpnjoGQET8YkQcNT0NnAd8D9gKTB/JsxG4uUxvBS4pRwOdBTxVNhXdBpwXESvLzt/zSpskqQ+62QR0IvC1iJju/4+Z+c2IuBe4MSI2AY8CF5X+twBvASaBZ4D3AmTmgYi4Ari39Lt8eoewJKl5Mci/BzA6OpruBJakuYmI+9oO2Z+VZwJLUqUMAEmqlAEgSZUyACSpUgaApJcYHtvW7xLUAANA0iEZBsuXASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgCfCErxoZAJJUKQNAkiplAEjqmpuJlhcDQNKsRsZHOGrt2IzLDIOlzwCQ9BKzvelreTEAJKlSBoAkVcoAkKRKGQCSVCkDQKqYR/LUzQCQpEoZAJJUKQNAEuCx/zUyACSpUgaAJFXKAJDUlZHxkX6XoB4zACSpUgaAJFXKAJCkSnUdABFxWETcHxHfKPOnRsTdEbE7Im6IiCNK+5FlfrIsH257jA+X9u9HxPm9HowkqXtz+QbwfmBX2/zHgKsycw3wBLCptG8CnsjM04CrSj8i4nTgYuA1wHrgMxFx2MLKlyTNV1cBEBGrgbcCXyjzAZwD3FS6jAMXlukNZZ6y/NzSfwNwfWY+m5k/AiaBdb0YhCRp7rr9BvAp4C+An5f544AnM/O5Mj8FrCrTq4DHAMryp0r/59tnWEeS1LCOARARvw/sy8z72ptn6Jodlh1qnfbn2xwROyJix/79+zuVJ0map26+AZwNvC0ifgxcT2vTz6eAYyJiRemzGthTpqeAkwHK8qOBA+3tM6zzvMzckpmjmTk6NDQ05wFJWnyeFLY8dAyAzPxwZq7OzGFaO3Fvz8x3AncAby/dNgI3l+mtZZ6y/PbMzNJ+cTlK6FRgDXBPz0Yiac68AFzdVnTuMqsPAddHxN8C9wPXlPZrgC9FxCStT/4XA2TmQxFxI/Aw8BxwaWb+bAHPL0lagDkFQGbeCdxZph9hhqN4MvOnwEWzrH8lcOVci5TUO8Nj2/jxR9/a7zI0ADwTWJIqZQBIUqUMAEmqlAEgSZUyACSpUgaApAUbHtvW7xI0DwaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJC+KloZcuA0CSKmUASFKlDACpMv4IjKYZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoBUgaau1+9ZwUuLASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQKqAF4DTTAwASaqUASBJlTIAJKlSBoCknmrqrGMtnAEgSZUyACSpUgaAJFWqYwBExMsj4p6I+LeIeCgi/qa0nxoRd0fE7oi4ISKOKO1HlvnJsny47bE+XNq/HxHnL9agJEmddfMN4FngnMz8deAMYH1EnAV8DLgqM9cATwCbSv9NwBOZeRpwVelHRJwOXAy8BlgPfCYiDuvlYCRJ3esYANnydJk9vNwSOAe4qbSPAxeW6Q1lnrL83IiI0n59Zj6bmT8CJoF1PRmFJGnOutoHEBGHRcQDwD5gAvgh8GRmPle6TAGryvQq4DGAsvwp4Lj29hnWaX+uzRGxIyJ27N+/f+4jkiR1pasAyMyfZeYZwGpan9rXztSt3Mcsy2ZrP/i5tmTmaGaODg0NdVOeJGke5nQUUGY+CdwJnAUcExEryqLVwJ4yPQWcDFCWHw0caG+fYR1Jy4w/Dzn4ujkKaCgijinTvwC8CdgF3AG8vXTbCNxcpreWecry2zMzS/vF5SihU4E1wD29GogkaW66+QZwEnBHROwE7gUmMvMbwIeAD0TEJK1t/NeU/tcAx5X2DwBjAJn5EHAj8DDwTeDSzPxZLwcj6QVekkGdrOjUITN3AmfO0P4IMxzFk5k/BS6a5bGuBK6ce5mSpF7zTGBJqpQBIEmVMgAkLRr3Qww2A0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgLRMHbV2rN8laMAZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkJYRr76puTAAJKlSBoAkVcoAkLToRsZH+l2CZmAASMuI1//RXBgAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQ1AivUzR4DABJqpQBIEmVMgAkqVIGgCRVygCQpEp1DICIODki7oiIXRHxUES8v7QfGxETEbG73K8s7RERV0fEZETsjIjXtT3WxtJ/d0RsXLxhSZI66eYbwHPAn2XmWuAs4NKIOB0YA7Zn5hpge5kHuABYU26bgc9CKzCAy4DXA+uAy6ZDQ5LUvI4BkJl7M/Nfy/T/ALuAVcAGYLx0GwcuLNMbgOuy5S7gmIg4CTgfmMjMA5n5BDABrO/paCQNPH8cZnDMaR9ARAwDZwJ3Aydm5l5ohQRwQum2CnisbbWp0jZb+8HPsTkidkTEjv3798+lPEnSHHQdABHxCuCfgD/NzP8+VNcZ2vIQ7S9uyNySmaOZOTo0NNRteZKkOeoqACLicFpv/v+QmV8tzY+XTTuU+32lfQo4uW311cCeQ7RLkvqgm6OAArgG2JWZn2xbtBWYPpJnI3BzW/sl5Wigs4Cnyiai24DzImJl2fl7XmmTtAAj4yNuV9e8rOiiz9nAu4EHI+KB0vaXwEeBGyNiE/AocFFZdgvwFmASeAZ4L0BmHoiIK4B7S7/LM/NAT0YhSZqzjgGQmf/CzNvvAc6doX8Cl87yWNcC186lQEnS4vBMYEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASGrc8Ng2hse29buM6hkAklQpA0CSKmUASFKlDABJqpQBIKkvjlo75mWs+8wAkKRKGQDSEuWnZy2UASBJlTIAJKlSBoC0BHkWrXrBAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgKS+8tfB+scAkKRKGQCSVKkV/S5AUmfTm0iOWjvGgxsf7HM1Wi78BiBJlTIAJPXdUWvH+l1ClQwASaqUASBJlTIAJKlSHQMgIq6NiH0R8b22tmMjYiIidpf7laU9IuLqiJiMiJ0R8bq2dTaW/rsjYuPiDEeS1K1uvgF8EVh/UNsYsD0z1wDbyzzABcCactsMfBZagQFcBrweWAdcNh0akqT+6BgAmfkd4MBBzRuA8TI9DlzY1n5dttwFHBMRJwHnAxOZeSAznwAmeGmoSJIaNN99ACdm5l6Acn9CaV8FPNbWb6q0zdYuSeqTXu8Ejhna8hDtL32AiM0RsSMiduzfv7+nxUmSXjDfAHi8bNqh3O8r7VPAyW39VgN7DtH+Epm5JTNHM3N0aGhonuVJkjqZbwBsBaaP5NkI3NzWfkk5Gugs4Kmyieg24LyIWFl2/p5X2iTpeV4aulndHAb6ZeC7wKsjYioiNgEfBd4cEbuBN5d5gFuAR4BJ4PPA+wAy8wBwBXBvuV1e2iR1MDI+0u8SGuVlIZrT8WqgmfmOWRadO0PfBC6d5XGuBa6dU3WSpEXj5aClAfXCJaD7XIiWLS8FIUmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEgaWLWdBNc0A0AaQL7xqQkGgCRVyjOBpQHi2b8vGB7b5r/DIvMbgCRVygCQpEoZAJJUKQNAkiplAEhSpQwAaUB47L+aZgBIWhL8reDe8zwAqc889r87rd8Kfmu/y1hW/AYgSZUyACSpUgaA1Efu+FU/GQBSH7hDU4PAAJCkShkAUsNGxkfKES2aLzed9YYBIEmVMgAkqVIGgCRVygCQGuJ268Xhv+v8GQCSVCkDQJIqZQBIi8jNE83y33tuDABJqpQBIPWYn0L7b2R8xNehC40HQESsj4jvR8RkRHg6pCT1SaMBEBGHAX8PXACcDrwjIk5vsgapV9o/Yfppc3CNjI948b1ZNP0NYB0wmZmPZOb/AtcDGxquQeqofROCb/TLh6/fizUdAKuAx9rmp0qbFsH0p575/tFPrzc8tu1F0930aX/znOn5D35TnX7c4bFtL6p7tun2x57tuRcy3S+3fv2DzT/pXx/9/OSuX117yOlbv/7BF7VPr9tN3X0Z2wy6+fta6P+dpSIys7kni7gIOD8z/6jMvxtYl5l/0tZnM7C5zL4a+C/gJ40V2bzjcXxLmeNb2pbr+F6VmUOdOjX9o/BTwMlt86uBPe0dMnMLsGV6PiJ2ZOZoM+U1z/EtbY5vaVvu4+uk6U1A9wJrIuLUiDgCuBjY2nANkiQa/gaQmc9FxB8DtwGHAddm5kNN1iBJaml6ExCZeQtwyxxW2dK5y5Lm+JY2x7e0LffxHVKjO4ElSYPDS0FIUqUGLgAi4tiImIiI3eV+5Sz9Ph4RD0XEroi4OiKi6VrnYw7jOyUivlXG93BEDDdb6fx0O77S95UR8Z8R8ekma1yIbsYXEWdExHfL3+fOiPjDftQ6F50u0RIRR0bEDWX53Uvl73FaF+P7QPl/tjMitkfEq/pRZ9MGLgCAMWB7Zq4Btpf5F4mI3wbOBl4L/Brwm8AbmyxyATqOr7gO+ERmrqV1BvW+hupbqG7HB3AF8M+NVNU73YzvGeCSzHwNsB74VEQc02CNc9LlJVo2AU9k5mnAVcDHmq1y/roc3/3AaGa+FrgJ+HizVfbHIAbABmC8TI8DF87QJ4GXA0cARwKHA483Ut3CdRxf+eNckZkTAJn5dGY+01yJC9LN60dE/AZwIvCthurqlY7jy8wfZObuMr2HVnh3PCmnj7q5REv7uG8Czl0q37rpYnyZeUfb/7G7aJ2jtOwNYgCcmJl7Acr9CQd3yMzvAncAe8vttszc1WiV89dxfMCvAE9GxFcj4v6I+ET5FLMUdBxfRLwM+DvgzxuurRe6ef2eFxHraH1Q+WEDtc1XN5doeb5PZj4HPAUc10h1CzfXS9BsAm5d1IoGROOHgQJExLeBX5ph0Ue6XP80YC0vpPRERPxOZn6nRyUuyELHR+t1eQNwJvAocAPwHuCaXtS3UD0Y3/uAWzLzsUH8ENmD8U0/zknAl4CNmfnzXtS2SGZ6EQ4+PLCbPoOq69oj4l3AKEtnk/KC9CUAMvNNsy2LiMcj4qTM3Fv+A8207fsPgLsy8+myzq3AWcBABEAPxjcF3J+Zj5R1vk5rfAMRAD0Y328Bb4iI9wGvAI6IiKczcyB+H6IH4yMiXglsA/4qM+9apFJ7peMlWtr6TEXECuBo4EAz5S1YN+MjIt5EK+TfmJnPNlRbXw3iJqCtwMYyvRG4eYY+jwJvjIgVEXE4rbReKpuAuhnfvcDKiJjebnwO8HADtfVCx/Fl5jsz85TMHAY+CFw3KG/+Xeg4vnKZk6/RGtdXGqxtvrq5REv7uN8O3J5L5ySijuOLiDOBzwFvy8ylcsDFwmXmQN1obVfcDuwu98eW9lHgC2X6MFov1i5ab4yf7HfdvRxfmX8zsBN4EPgicES/a+/l+Nr6vwf4dL/r7uX4gHcB/wc80HY7o9+1dxjXW4Af0NpX8ZHSdjmtN0RoHXTxFWASuAf45X7X3OPxfZvWgSTTr9fWftfcxM0zgSWpUoO4CUiS1AADQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkSv0/dF/+riHvHM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(quantize.get_model_weights(model2), bins=100);\n",
    "plt.hist(model1_param, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model3 = load_model(save_path + 'mnist_custom/mnist_keras.h5')\n",
    "model3_param = quantize.get_model_weights(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 2550.\n",
    "x_test /= 2550.\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model4.add(layers.BatchNormalization())\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model4.add(layers.BatchNormalization())\n",
    "model4.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(layers.Dropout(0.25))\n",
    "\n",
    "model4.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model4.add(layers.BatchNormalization())\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.BatchNormalization())\n",
    "model4.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(layers.Dropout(0.25))\n",
    "\n",
    "# pmo4del.add(layers.Flatten())\n",
    "model4.add(layers.GlobalMaxPooling2D())\n",
    "model4.add(layers.Dropout(0.25))\n",
    "model4.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001)\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 2.5237 - acc: 0.4670 - val_loss: 0.2471 - val_acc: 0.9385\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.8136 - acc: 0.7648 - val_loss: 0.1309 - val_acc: 0.9630\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.4819 - acc: 0.8599 - val_loss: 0.0926 - val_acc: 0.9760\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.3460 - acc: 0.9005 - val_loss: 0.0733 - val_acc: 0.9784\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.2627 - acc: 0.9232 - val_loss: 0.0709 - val_acc: 0.9796s: 0.2633 - acc:\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.2214 - acc: 0.9361 - val_loss: 0.0521 - val_acc: 0.9842\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.1849 - acc: 0.9468 - val_loss: 0.0544 - val_acc: 0.9836\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.1596 - acc: 0.9546 - val_loss: 0.0442 - val_acc: 0.9863\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1418 - acc: 0.9600 - val_loss: 0.0501 - val_acc: 0.9841\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1305 - acc: 0.9634 - val_loss: 0.0392 - val_acc: 0.98850.1303 - acc: 0.\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1163 - acc: 0.9674 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1085 - acc: 0.9695 - val_loss: 0.0344 - val_acc: 0.9903s: 0.1086 - acc: 0\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1040 - acc: 0.9708 - val_loss: 0.0295 - val_acc: 0.9908\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0987 - acc: 0.9721 - val_loss: 0.0318 - val_acc: 0.9900s - los - ETA: 4s - loss: 0.0992 - acc: 0 - ETA: 4s - loss: 0. - ETA: 3s - loss: 0.09\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0928 - acc: 0.9738 - val_loss: 0.0318 - val_acc: 0.9895- loss: 0.0928 - acc:\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0858 - acc: 0.9755 - val_loss: 0.0338 - val_acc: 0.9884\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0809 - acc: 0.9767 - val_loss: 0.0299 - val_acc: 0.9905\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0830 - acc: 0.9769 - val_loss: 0.0294 - val_acc: 0.99142 - acc - ETA: 5s - loss: 0.0811 - acc: 0. - ETA: 5s - loss: - ETA: 1s - loss: 0.0827 - acc: 0. - ETA: 1s - loss: \n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0751 - acc: 0.9786 - val_loss: 0.0281 - val_acc: 0.9902\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0750 - acc: 0.9790 - val_loss: 0.0268 - val_acc: 0.9913\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFU9JREFUeJzt3X+wXPV53/H3xxJgN/6BMBeKJdnCqdIYV4lwFZnWk8YxDgg6DWTGTKGNrXroKK6hTaZJpnKSGRy7zMSdOkw8IaSkqBaZJJg4cdCAbCJjPKlnyg/hyhKCEF1jamRpQIkwNqUlhTz9435vvFzuj71Xe/fu1Xm/Znb27HO+5+xzVlf72T3n7G6qCklS97xqqRuQJC0NA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6qiVS93AbM4888xat27dUrchScvKQw899JdVNTbXuJEOgHXr1rF3796lbkOSlpUk/6ufce4CkqSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yAKST1IadG5a6BY04A0CSOsoAkDrAdwOajgEgSR1lAEgnEV/paz7mDIAkr07yQJKvJTmY5Fdb/dNJvpFkX7tsbPUk+VSS8ST7k7yjZ11bkxxql62Lt1mS+mFgdFs/vwfwAvCeqnouySnAV5J8vs37xar67JTxlwDr2+WdwE3AO5OcAVwHbAIKeCjJrqp6ZhAbIkmanznfAdSE59rNU9qlZlnkMuDWttx9wOlJzgEuBvZU1fH2pL8H2HJi7UuaL1/1a1JfxwCSrEiyD3iaiSfx+9us69tunhuSnNZqq4EnexY/3Goz1SVJS6CvAKiql6pqI7AG2JzkHwAfAX4Q+BHgDOA/tOGZbhWz1F8mybYke5PsPXbsWD/tSZIWYF5nAVXVt4EvA1uq6mjbzfMC8N+AzW3YYWBtz2JrgCOz1Kfex81VtamqNo2NzfmbxpKkBernLKCxJKe36dcA7wX+vO3XJ0mAy4GH2yK7gA+0s4EuAJ6tqqPA3cBFSVYlWQVc1GqSpCXQz1lA5wA7k6xgIjBur6o7k3wpyRgTu3b2AR9q43cDlwLjwPPABwGq6niSjwMPtnEfq6rjg9sUqZs27NzAga0HlroNLUNzBkBV7QfOn6b+nhnGF3DNDPN2ADvm2aOkKWZ70l+3/S4AXve2YXak5chPAksdNBkSvTw9tHv62QUkaZny3YBm4zsASeooA0CSOsoAkDpiuv3+6jYDQDpJ+ASv+TIAJKmjDABJ6igDQFrG3O2jE2EASFJHGQCS1FEGgNRx7kbqLgNAkjrKAJCWickva/MVuwbFAJCWgWE96U/ej98M2g0GgCR1lAEgSR1lAEhSRxkAktRRcwZAklcneSDJ15IcTPKrrX5ukvuTHErymSSntvpp7fZ4m7+uZ10fafXHkly8WBsl6cR5ttHJr593AC8A76mqHwY2AluSXAB8ArihqtYDzwBXt/FXA89U1d8DbmjjSHIecCXwdmAL8FtJVgxyYyRJ/ZszAGrCc+3mKe1SwHuAz7b6TuDyNn1Zu02bf2GStPptVfVCVX0DGAc2D2QrJEnz1tcxgCQrkuwDngb2AF8Hvl1VL7Yhh4HVbXo18CRAm/8s8Mbe+jTLSBpRfibg5NVXAFTVS1W1EVjDxKv2t003rF1nhnkz1V8mybYke5PsPXbsWD/tSZIWYF5nAVXVt4EvAxcApydZ2WatAY606cPAWoA2/w3A8d76NMv03sfNVbWpqjaNjY3Npz1J0jz0cxbQWJLT2/RrgPcCjwL3Au9rw7YCd7TpXe02bf6Xqqpa/cp2ltC5wHrggUFtiCRpflbOPYRzgJ3tjJ1XAbdX1Z1JHgFuS/Ifgf8J3NLG3wL8bpJxJl75XwlQVQeT3A48ArwIXFNVLw12cyRJ/ZozAKpqP3D+NPXHmeYsnqr6v8AVM6zreuD6+bcpSRo0PwksjTDPwNFiMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASXPy5yFPTgaANKJ80tViMwAkqaMMAGnE+AVwGhYDQJI6ygCQpI4yACSpowwASeooA0AaIZ76qWEyACT1bcPODYbUSWTOAEiyNsm9SR5NcjDJz7b6R5N8K8m+drm0Z5mPJBlP8liSi3vqW1ptPMn2xdkkSVI/VvYx5kXg56vqq0leBzyUZE+bd0NV/efewUnOA64E3g68Cfhikh9os28EfgI4DDyYZFdVPTKIDZEkzc+cAVBVR4Gjbfq7SR4FVs+yyGXAbVX1AvCNJOPA5jZvvKoeB0hyWxtrAEjSEpjXMYAk64Dzgftb6dok+5PsSLKq1VYDT/YsdrjVZqpPvY9tSfYm2Xvs2LH5tCdJmoe+AyDJa4E/An6uqr4D3AR8P7CRiXcIn5wcOs3iNUv95YWqm6tqU1VtGhsb67c9SdI89XMMgCSnMPHk/3tV9ccAVfVUz/zfAe5sNw8Da3sWXwMcadMz1SVJQ9bPWUABbgEerapf76mf0zPsp4CH2/Qu4MokpyU5F1gPPAA8CKxPcm6SU5k4ULxrMJshSZqvft4BvAt4P3Agyb5W+yXgqiQbmdiN8wTwMwBVdTDJ7Uwc3H0RuKaqXgJIci1wN7AC2FFVBwe4LZKkeejnLKCvMP3++92zLHM9cP009d2zLSdJGh4/CSxJHWUASFJHGQDSEtuwc4O/AqYlYQBIUkcZAJLUUQaApAVxt9XyZwBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAkhZs3fa7lroFnQADQJI6ygCQpI4yACSpo+YMgCRrk9yb5NEkB5P8bKufkWRPkkPtelWrJ8mnkown2Z/kHT3r2trGH0qydfE2S5I0l37eAbwI/HxVvQ24ALgmyXnAduCeqloP3NNuA1wCrG+XbcBNMBEYwHXAO4HNwHWToSFJGr45A6CqjlbVV9v0d4FHgdXAZcDONmwncHmbvgy4tSbcB5ye5BzgYmBPVR2vqmeAPcCWgW6NJKlv8zoGkGQdcD5wP3B2VR2FiZAAzmrDVgNP9ix2uNVmqkuSlkDfAZDktcAfAT9XVd+Zbeg0tZqlPvV+tiXZm2TvsWPH+m1PWlb8IXiNgr4CIMkpTDz5/15V/XErP9V27dCun271w8DansXXAEdmqb9MVd1cVZuqatPY2Nh8tkWSNA/9nAUU4Bbg0ar69Z5Zu4DJM3m2Anf01D/Qzga6AHi27SK6G7goyap28PeiVpMkLYGVfYx5F/B+4ECSfa32S8CvAbcnuRr4JnBFm7cbuBQYB54HPghQVceTfBx4sI37WFUdH8hWSJLmbc4AqKqvMP3+e4ALpxlfwDUzrGsHsGM+DUqSFoefBJakjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkDQQ/kD88mMASDphfrPp8mQASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIA3Jhp0bPF9eI8UAkKSOmjMAkuxI8nSSh3tqH03yrST72uXSnnkfSTKe5LEkF/fUt7TaeJLtg98USdJ89PMO4NPAlmnqN1TVxnbZDZDkPOBK4O1tmd9KsiLJCuBG4BLgPOCqNlaStERWzjWgqv4sybo+13cZcFtVvQB8I8k4sLnNG6+qxwGS3NbGPjLvjiVJA3EixwCuTbK/7SJa1WqrgSd7xhxutZnqkqQlstAAuAn4fmAjcBT4ZKtnmrE1S/0VkmxLsjfJ3mPHji2wPUnSXBYUAFX1VFW9VFV/A/wO39vNcxhY2zN0DXBklvp06765qjZV1aaxsbGFtCdJ6sOCAiDJOT03fwqYPENoF3BlktOSnAusBx4AHgTWJzk3yalMHCjetfC2JY0qP++wfMx5EDjJHwDvBs5Mchi4Dnh3ko1M7MZ5AvgZgKo6mOR2Jg7uvghcU1UvtfVcC9wNrAB2VNXBgW+NJKlv/ZwFdNU05VtmGX89cP009d3A7nl1J0laNH4SWJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgCkReSHojTKDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6qg5AyDJjiRPJ3m4p3ZGkj1JDrXrVa2eJJ9KMp5kf5J39CyztY0/lGTr4myOpFHit6GOtn7eAXwa2DKlth24p6rWA/e02wCXAOvbZRtwE0wEBnAd8E5gM3DdZGhIkpbGnAFQVX8GHJ9SvgzY2aZ3Apf31G+tCfcBpyc5B7gY2FNVx6vqGWAPrwwVSdIQLfQYwNlVdRSgXZ/V6quBJ3vGHW61meqvkGRbkr1J9h47dmyB7UmS5jLog8CZplaz1F9ZrLq5qjZV1aaxsbGBNicNg/u8tVwsNACeart2aNdPt/phYG3PuDXAkVnqkqQlstAA2AVMnsmzFbijp/6BdjbQBcCzbRfR3cBFSVa1g78XtZokaYmsnGtAkj8A3g2cmeQwE2fz/Bpwe5KrgW8CV7Thu4FLgXHgeeCDAFV1PMnHgQfbuI9V1dQDy5KkIZozAKrqqhlmXTjN2AKumWE9O4Ad8+pOkrRo/CSwJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAkobC3wYYPQaANAA+sWk5MgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeqoEwqAJE8kOZBkX5K9rXZGkj1JDrXrVa2eJJ9KMp5kf5J3DGIDJEkLM4h3AD9eVRuralO7vR24p6rWA/e02wCXAOvbZRtw0wDuW1oyG3ZuYN32u5a6DWnBFmMX0GXAzja9E7i8p35rTbgPOD3JOYtw/5KkPpxoABTwp0keSrKt1c6uqqMA7fqsVl8NPNmz7OFWkyQtgZUnuPy7qupIkrOAPUn+fJaxmaZWrxg0ESTbAN785jefYHuSRtHk12cf2HpgiTvpthN6B1BVR9r108DngM3AU5O7dtr10234YWBtz+JrgCPTrPPmqtpUVZvGxsZOpD1J0iwWHABJvi/J6yangYuAh4FdwNY2bCtwR5veBXygnQ10AfDs5K4iSdLwncguoLOBzyWZXM/vV9UXkjwI3J7kauCbwBVt/G7gUmAceB744AnctyTpBC04AKrqceCHp6n/FXDhNPUCrlno/UmSBstPAktSRxkA0jz44S+dTAwASUtqw84Nf3taqIbLAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yAKQ5eOqnTlYGgCR1lAEgSR1lAEgaGeu23+WHwobIAJBm4H5/newMAGkavgpVFxgAktRRBoAkdZQBIDXu9hktHoNZfAaA1MMnndFiKC8uA0Cd55P+6PPfaHEMPQCSbEnyWJLxJNuHff8SfO8JxVeYy8fkv5VhMDhDDYAkK4AbgUuA84Crkpw3zB7UTb1P9D7pL3+GwWAM+x3AZmC8qh6vqr8GbgMuG3IPOon1fnHb1C9x88ni5GQYLNywA2A18GTP7cOtppPITK+2p/vt18mP/k/Wp46ZOj3dk/uSfFvnR98wkNU8+oNvm3a6nzEzjf/8n/zCzNOt71dMTzN+6jpfdn8D2v5B6w2D+U5Pmvq3NPn3NVmf79/aKAdTqmp4d5ZcAVxcVf+63X4/sLmq/m3PmG3Atnbz7wOPTVnNmcBfDqHdEzHqPY56f2CPgzDq/cHo9zjq/cH0Pb6lqsbmWnDl4vQzo8PA2p7ba4AjvQOq6mbg5plWkGRvVW1anPYGY9R7HPX+wB4HYdT7g9HvcdT7gxPrcdi7gB4E1ic5N8mpwJXAriH3IEliyO8AqurFJNcCdwMrgB1VdXCYPUiSJgx7FxBVtRvYfQKrmHH30AgZ9R5HvT+wx0EY9f5g9Hsc9f7gBHoc6kFgSdLo8KsgJKmjRj4AkpyRZE+SQ+161QzjXkqyr12GemC53x7b2Ncn+VaS3xyl/pK8JclD7fE7mORDw+pvHj1uTPI/Wn/7k/zzUeqvjftCkm8nuXOIvc369SpJTkvymTb//iTrhtVbn/39kyRfTfJikvcNs7d59PjvkzzS/u7uSfKWEevvQ0kOtP+/X+n7GxaqaqQvwH8Ctrfp7cAnZhj33Kj32Ob/BvD7wG+OUn/AqcBpbfq1wBPAm0asxx8A1rfpNwFHgdNHpb8270LgnwF3DqmvFcDXgbe2f8OvAedNGfNh4Lfb9JXAZ4b479pPf+uAHwJuBd43rN7m2eOPA3+nTf+bEXwMX98z/ZPAF/pZ98i/A2DiqyJ2tumdwOVL2MtM+uoxyT8Ezgb+dEh9TZqzv6r666p6od08jeG/O+ynx7+oqkNt+gjwNDDnh12G1V/r6x7gu0PqCfr7epXe3j8LXJgko9JfVT1RVfuBvxlST1P10+O9VfV8u3kfE59hGqX+vtNz8/uAvg7uLocAOLuqjgK067NmGPfqJHuT3Jdk2CExZ49JXgV8EvjFIfcGfT6GSdYm2c/E13V8oj3JjlSPk5JsZuLV0NeH0BvMs78h6ufrVf52TFW9CDwLvHEo3S2Pr3+Zb49XA59f1I5erq/+klyT5OtMvFv9d/2seOingU4nyReBvzvNrF+ex2reXFVHkrwV+FKSA1U1sCeHAfT4YWB3VT25GC++BvEYVtWTwA8leRPwJ0k+W1VPjVKPbT3nAL8LbK2qgb1qHFR/QzbdH9PUV3/9jFksS3nf/eq7xyQ/DWwCfmxRO5pyt9PUXtFfVd0I3JjkXwC/Amyda8UjEQBV9d6Z5iV5Ksk5VXW0/cd/eoZ1HGnXjyf5MnA+A3x1OIAe/xHwo0k+zMQ+9lOTPFdVA/lNhEE8hj3rOpLkIPCjTOwyGIhB9Jjk9cBdwK9U1X2D6m1Q/S2BOb9epWfM4SQrgTcAx4fTXl/9LbW+ekzyXiZeDPxYz+7SYZjvY3gbcFM/K14Ou4B28b0k2wrcMXVAklVJTmvTZwLvAh4ZWod99FhV/7Kq3lxV64BfAG4d1JP/IPpLsibJa9r0KiYew6lfxLeY+unxVOBzTDx2fzjE3qCP/pZIP1+v0tv7+4AvVTtaOCL9LbU5e0xyPvBfgJ+sqmGHfz/9re+5+U+BQ32teVhHsk/gCPgbgXvaBt0DnNHqm4D/2qb/MXCAiaPjB4CrR63HKeP/FcM9C6ifx/AngP3tMdwPbBu1xxD4aeD/Aft6LhtHpb92+78Dx4D/w8Qrt4uH0NulwF8w8Y73l1vtY0w8WQG8GvhDYBx4AHjrkP9t5+rvR9pj9b+BvwIODrO/Pnv8IvBUz9/drhHr7zeAg623e4G397NePwksSR21HHYBSZIWgQEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUf8fuc60QR8t95MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(quantize.get_model_weights(model4), bins=100);\n",
    "plt.hist(model3_param, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
