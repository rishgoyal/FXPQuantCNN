{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras import layers\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import regularizers, callbacks\n",
    "import sys\n",
    "sys.path.append('C:/Users/320060820/experiments/')\n",
    "from train_model import *\n",
    "# from inception_model import get_model\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to restart layer numbering\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../test_models/'\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "reduced_training_size_factor = 1\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(300))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3434 - acc: 0.8981 - val_loss: 0.1410 - val_acc: 0.9584\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1700 - acc: 0.9492 - val_loss: 0.0961 - val_acc: 0.9718\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1306 - acc: 0.9592 - val_loss: 0.0819 - val_acc: 0.9753\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1099 - acc: 0.9663 - val_loss: 0.0682 - val_acc: 0.9776\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0952 - acc: 0.9691 - val_loss: 0.0681 - val_acc: 0.9784\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0883 - acc: 0.9725 - val_loss: 0.0643 - val_acc: 0.9784\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0792 - acc: 0.9743 - val_loss: 0.0610 - val_acc: 0.9800\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0720 - acc: 0.9769 - val_loss: 0.0603 - val_acc: 0.9809\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0699 - acc: 0.9778 - val_loss: 0.0582 - val_acc: 0.9809\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0655 - acc: 0.9787 - val_loss: 0.0519 - val_acc: 0.9837\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0646 - acc: 0.9785 - val_loss: 0.0552 - val_acc: 0.9813\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0607 - acc: 0.9803 - val_loss: 0.0541 - val_acc: 0.9835\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0545 - acc: 0.9816 - val_loss: 0.0567 - val_acc: 0.9823\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0552 - acc: 0.9817 - val_loss: 0.0533 - val_acc: 0.9841\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0535 - acc: 0.9821 - val_loss: 0.0535 - val_acc: 0.9850\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0518 - acc: 0.9823 - val_loss: 0.0519 - val_acc: 0.9837\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0486 - acc: 0.9833 - val_loss: 0.0501 - val_acc: 0.9854\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0490 - acc: 0.9836 - val_loss: 0.0534 - val_acc: 0.9848\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0472 - acc: 0.9845 - val_loss: 0.0517 - val_acc: 0.9838\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0454 - acc: 0.9850 - val_loss: 0.0530 - val_acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test))\n",
    "model.save(save_path + 'mnist_dense_3layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.append(model.layers[2].get_weights()[0], model.layers[2].get_weights()[1])\n",
    "weights = np.append(weights, model.layers[-1].get_weights()[0])\n",
    "weights = np.append(weights, model.layers[-1].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(weights, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 layer dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(300, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3767 - acc: 0.8844 - val_loss: 0.1340 - val_acc: 0.9573\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1814 - acc: 0.9447 - val_loss: 0.0926 - val_acc: 0.9714\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1459 - acc: 0.9547 - val_loss: 0.0796 - val_acc: 0.9746\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1225 - acc: 0.9620 - val_loss: 0.0748 - val_acc: 0.9775\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1101 - acc: 0.9655 - val_loss: 0.0651 - val_acc: 0.9784\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1068 - acc: 0.9660 - val_loss: 0.0688 - val_acc: 0.9796\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0923 - acc: 0.9710 - val_loss: 0.0628 - val_acc: 0.9808\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0895 - acc: 0.9722 - val_loss: 0.0621 - val_acc: 0.9792\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0834 - acc: 0.9729 - val_loss: 0.0650 - val_acc: 0.9805\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0787 - acc: 0.9742 - val_loss: 0.0619 - val_acc: 0.9817\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0763 - acc: 0.9747 - val_loss: 0.0640 - val_acc: 0.9820\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0730 - acc: 0.9763 - val_loss: 0.0558 - val_acc: 0.9835\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0715 - acc: 0.9772 - val_loss: 0.0650 - val_acc: 0.9821\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0652 - acc: 0.9790 - val_loss: 0.0560 - val_acc: 0.9835\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0674 - acc: 0.9783 - val_loss: 0.0567 - val_acc: 0.9824\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0632 - acc: 0.9795 - val_loss: 0.0618 - val_acc: 0.9817\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0626 - acc: 0.9799 - val_loss: 0.0554 - val_acc: 0.9846\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0637 - acc: 0.9797 - val_loss: 0.0599 - val_acc: 0.9835\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0526 - val_acc: 0.9849\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0595 - acc: 0.9808 - val_loss: 0.0596 - val_acc: 0.9823\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test))\n",
    "model.save(save_path + 'test_models/mnist_custom/mnist_dense_4layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmodel = Sequential()\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "pmodel.add(layers.GlobalAveragePooling2D())\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "pmodel.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "pmodel.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.2663 - acc: 0.9358 - val_loss: 0.0811 - val_acc: 0.9766\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0736 - acc: 0.9791 - val_loss: 0.0641 - val_acc: 0.9821\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0566 - acc: 0.9828 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0452 - acc: 0.9863 - val_loss: 0.0376 - val_acc: 0.9857\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0428 - acc: 0.9873 - val_loss: 0.0339 - val_acc: 0.9887\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0394 - acc: 0.9883 - val_loss: 0.0249 - val_acc: 0.9911\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0361 - acc: 0.9888 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0330 - acc: 0.9899 - val_loss: 0.0216 - val_acc: 0.9927\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0320 - acc: 0.9901 - val_loss: 0.0265 - val_acc: 0.9913\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0316 - acc: 0.9897 - val_loss: 0.0211 - val_acc: 0.9927\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0232 - val_acc: 0.9917\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0272 - acc: 0.9917 - val_loss: 0.0196 - val_acc: 0.9935\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.0227 - val_acc: 0.9926\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0268 - val_acc: 0.9908\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.0222 - acc: 0.9931 - val_loss: 0.0216 - val_acc: 0.9931\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.0226 - acc: 0.9927 - val_loss: 0.0174 - val_acc: 0.9945\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0207 - acc: 0.9931 - val_loss: 0.0162 - val_acc: 0.9949\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0230 - val_acc: 0.9920\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0169 - val_acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "history = pmodel.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test))\n",
    "pmodel.save(save_path + 'mnist_cnn_simple.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 66,410\n",
      "Trainable params: 66,026\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amodel = Sequential()\n",
    "amodel.add(layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "amodel.add(layers.Activation('relu'))\n",
    "amodel.add(layers.BatchNormalization())\n",
    "amodel.add(layers.Conv2D(32, (3, 3)))\n",
    "amodel.add(layers.Activation('relu'))\n",
    "amodel.add(layers.BatchNormalization())\n",
    "amodel.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "amodel.add(layers.Dropout(0.25))\n",
    "\n",
    "amodel.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "amodel.add(layers.Activation('relu'))\n",
    "amodel.add(layers.BatchNormalization())\n",
    "amodel.add(layers.Conv2D(64, (3, 3)))\n",
    "amodel.add(layers.Activation('relu'))\n",
    "amodel.add(layers.BatchNormalization())\n",
    "amodel.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "amodel.add(layers.Dropout(0.25))\n",
    "\n",
    "amodel.add(layers.GlobalAveragePooling2D())\n",
    "amodel.add(layers.Dropout(0.25))\n",
    "amodel.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "amodel.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amodel.layers), len(pmodel.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "amodel.set_weights(pmodel.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016879658109934827, 0.9948]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amodel.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 66,410\n",
      "Trainable params: 66,026\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "amodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "amodel.save(save_path + 'test_models/mnist_custom/mnist_cnn_simple_sepact.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "pmodel = Sequential()\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "# pmodel.add(layers.Flatten())\n",
    "pmodel.add(layers.GlobalMaxPooling2D())\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "pmodel.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001)\n",
    "\n",
    "pmodel.compile(loss='categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 2.9201 - acc: 0.4229 - val_loss: 0.2562 - val_acc: 0.9374\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.8857 - acc: 0.7502 - val_loss: 0.1367 - val_acc: 0.9631\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.5296 - acc: 0.8465 - val_loss: 0.0960 - val_acc: 0.9735\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.3653 - acc: 0.8937 - val_loss: 0.0754 - val_acc: 0.97930.3678 - acc - ETA: 0s - loss: 0.3666 - acc: 0\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.2914 - acc: 0.9154 - val_loss: 0.0627 - val_acc: 0.9835: 0.2945 - \n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.2334 - acc: 0.9304 - val_loss: 0.0567 - val_acc: 0.9836\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.1946 - acc: 0.9435 - val_loss: 0.0483 - val_acc: 0.9862\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1700 - acc: 0.9513 - val_loss: 0.0409 - val_acc: 0.9885\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1487 - acc: 0.9587 - val_loss: 0.0368 - val_acc: 0.9883\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1309 - acc: 0.9633 - val_loss: 0.0369 - val_acc: 0.9883\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.1246 - acc: 0.9653 - val_loss: 0.0348 - val_acc: 0.9889\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.1147 - acc: 0.9693 - val_loss: 0.0330 - val_acc: 0.9899\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.1080 - acc: 0.9698 - val_loss: 0.0326 - val_acc: 0.9898\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.1006 - acc: 0.9719 - val_loss: 0.0296 - val_acc: 0.9904\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.0943 - acc: 0.9735 - val_loss: 0.0325 - val_acc: 0.9899\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0916 - acc: 0.9740 - val_loss: 0.0286 - val_acc: 0.9910\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0902 - acc: 0.9745 - val_loss: 0.0304 - val_acc: 0.9904\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0846 - acc: 0.9761 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0300 - val_acc: 0.9909\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0751 - acc: 0.9784 - val_loss: 0.0278 - val_acc: 0.9911cc: 0.97\n"
     ]
    }
   ],
   "source": [
    "history = pmodel.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True, \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmodel.save(save_path + 'mnist_custom/mnist_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
