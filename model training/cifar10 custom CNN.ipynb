{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, callbacks\n",
    "import sys\n",
    "sys.path.append('C:/Users/320060820/experiments/')\n",
    "from train_model import *\n",
    "from inception_model import get_model\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to restart layer numbering\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN = True\n",
    "save_path = '../model archive/test/'\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "reduced_training_size_factor = 1\n",
    "batch_size = 32\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 25500.\n",
    "x_test /= 25500.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# (x_train_resize, y_train), (x_test_resize, y_test) = convert_data(train_data, test_data, \n",
    "#                                                                   batch_size, num_classes, \n",
    "#                                                                   reduced_training_size_factor,\n",
    "#                                                                  input_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,251,626\n",
      "Trainable params: 1,251,242\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\320060820\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 26s 521us/step - loss: 1.8585 - acc: 0.3692 - val_loss: 1.4309 - val_acc: 0.5022\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 1.4354 - acc: 0.4963 - val_loss: 1.3408 - val_acc: 0.5600\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 1.2737 - acc: 0.5603 - val_loss: 1.1712 - val_acc: 0.6005\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 1.1621 - acc: 0.5971 - val_loss: 1.0421 - val_acc: 0.6467\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 1.0804 - acc: 0.6282 - val_loss: 1.0234 - val_acc: 0.6544\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 1.0191 - acc: 0.6491 - val_loss: 0.9185 - val_acc: 0.6861\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.9667 - acc: 0.6658 - val_loss: 0.8854 - val_acc: 0.6987\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.9259 - acc: 0.6821 - val_loss: 0.8803 - val_acc: 0.7025\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.8842 - acc: 0.6984 - val_loss: 0.8534 - val_acc: 0.7225\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.8560 - acc: 0.7083 - val_loss: 0.7656 - val_acc: 0.7444\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.8232 - acc: 0.7176 - val_loss: 0.7970 - val_acc: 0.7326\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.7981 - acc: 0.7282 - val_loss: 0.8343 - val_acc: 0.7295\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.7747 - acc: 0.7359 - val_loss: 0.8118 - val_acc: 0.7441\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.7532 - acc: 0.7438 - val_loss: 0.7297 - val_acc: 0.7596\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.7427 - acc: 0.7476 - val_loss: 0.7659 - val_acc: 0.7490\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.7194 - acc: 0.7572 - val_loss: 0.8010 - val_acc: 0.7507\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.7024 - acc: 0.7591 - val_loss: 0.6969 - val_acc: 0.7695\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.6838 - acc: 0.7661 - val_loss: 0.7330 - val_acc: 0.7609\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.6763 - acc: 0.7695 - val_loss: 0.6756 - val_acc: 0.7739\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.6610 - acc: 0.7762 - val_loss: 0.6698 - val_acc: 0.7788\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.6546 - acc: 0.7788 - val_loss: 0.7256 - val_acc: 0.7683\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.6303 - acc: 0.7842 - val_loss: 0.6956 - val_acc: 0.7772\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.6211 - acc: 0.7893 - val_loss: 0.6977 - val_acc: 0.7767\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.6086 - acc: 0.7927 - val_loss: 0.7145 - val_acc: 0.7707\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.6034 - acc: 0.7967 - val_loss: 0.6462 - val_acc: 0.7900\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.5928 - acc: 0.7980 - val_loss: 0.6707 - val_acc: 0.7806\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.5827 - acc: 0.8020 - val_loss: 0.6276 - val_acc: 0.7979\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 25s 490us/step - loss: 0.5736 - acc: 0.8051 - val_loss: 0.6319 - val_acc: 0.7889\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.5627 - acc: 0.8104 - val_loss: 0.6062 - val_acc: 0.7971\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.5586 - acc: 0.8106 - val_loss: 0.6745 - val_acc: 0.7858\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.5531 - acc: 0.8111 - val_loss: 0.6199 - val_acc: 0.8000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.5421 - acc: 0.8146 - val_loss: 0.6214 - val_acc: 0.7967\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.5384 - acc: 0.8173 - val_loss: 0.6256 - val_acc: 0.7948\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 0.5312 - acc: 0.8195 - val_loss: 0.6037 - val_acc: 0.8003\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 0.5274 - acc: 0.8202 - val_loss: 0.6146 - val_acc: 0.7993\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.5233 - acc: 0.8215 - val_loss: 0.6009 - val_acc: 0.8039\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 25s 497us/step - loss: 0.5163 - acc: 0.8258 - val_loss: 0.5814 - val_acc: 0.8079\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 26s 520us/step - loss: 0.5096 - acc: 0.8277 - val_loss: 0.6071 - val_acc: 0.8040\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 24s 490us/step - loss: 0.5065 - acc: 0.8277 - val_loss: 0.6012 - val_acc: 0.8024\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.4961 - acc: 0.8300 - val_loss: 0.6090 - val_acc: 0.8027\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.4975 - acc: 0.8299 - val_loss: 0.6107 - val_acc: 0.8005\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.4820 - acc: 0.8356 - val_loss: 0.6207 - val_acc: 0.8005\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.4779 - acc: 0.8364 - val_loss: 0.6170 - val_acc: 0.8027\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.4774 - acc: 0.8387 - val_loss: 0.6117 - val_acc: 0.8082\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.4641 - acc: 0.8405 - val_loss: 0.5789 - val_acc: 0.8160\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.4581 - acc: 0.8453 - val_loss: 0.5793 - val_acc: 0.8138\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.4499 - acc: 0.8475 - val_loss: 0.5961 - val_acc: 0.8115\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 24s 489us/step - loss: 0.4426 - acc: 0.8509 - val_loss: 0.6059 - val_acc: 0.8108\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.4369 - acc: 0.8504 - val_loss: 0.6332 - val_acc: 0.8051\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.4306 - acc: 0.8548 - val_loss: 0.5971 - val_acc: 0.8122\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True, \n",
    "                    validation_data=(x_test, y_test))\n",
    "# model.save(save_path + 'keras_cifar10_example_dense_rmsprop_batchnorm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5970991486787796\n",
      "Test accuracy 0.8122\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Dense layers with Max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmodel = Sequential()\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "pmodel.add(layers.BatchNormalization())\n",
    "pmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "\n",
    "# pmodel.add(layers.Flatten())\n",
    "pmodel.add(layers.GlobalMaxPooling2D())\n",
    "pmodel.add(layers.Dropout(0.25))\n",
    "pmodel.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001)\n",
    "\n",
    "pmodel.compile(loss='categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 66,986\n",
      "Trainable params: 66,602\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 3.2269 - acc: 0.1974 - val_loss: 1.8132 - val_acc: 0.3351\n",
      "Epoch 2/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 2.1700 - acc: 0.2617 - val_loss: 1.7403 - val_acc: 0.3872ss: 2.1711 - acc: 0.\n",
      "Epoch 3/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.9442 - acc: 0.3107 - val_loss: 1.8437 - val_acc: 0.3448\n",
      "Epoch 4/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.7938 - acc: 0.3581 - val_loss: 4.6717 - val_acc: 0.1776\n",
      "Epoch 5/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.6938 - acc: 0.3917 - val_loss: 3.5966 - val_acc: 0.1399\n",
      "Epoch 6/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.6032 - acc: 0.4244 - val_loss: 2.0850 - val_acc: 0.3195\n",
      "Epoch 7/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.5484 - acc: 0.4448 - val_loss: 1.9380 - val_acc: 0.3053\n",
      "Epoch 8/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.4881 - acc: 0.4663 - val_loss: 2.3160 - val_acc: 0.2934\n",
      "Epoch 9/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.4443 - acc: 0.4841 - val_loss: 2.1573 - val_acc: 0.2877\n",
      "Epoch 10/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.4098 - acc: 0.4965 - val_loss: 1.5826 - val_acc: 0.4212\n",
      "Epoch 11/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.3684 - acc: 0.5123 - val_loss: 3.4895 - val_acc: 0.2528\n",
      "Epoch 12/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.3373 - acc: 0.5232 - val_loss: 2.0749 - val_acc: 0.3196\n",
      "Epoch 13/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.3102 - acc: 0.5337 - val_loss: 1.9788 - val_acc: 0.2873\n",
      "Epoch 14/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.2866 - acc: 0.5459 - val_loss: 2.8510 - val_acc: 0.2809\n",
      "Epoch 15/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.2717 - acc: 0.5491 - val_loss: 2.9526 - val_acc: 0.2218\n",
      "Epoch 16/70\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 1.2515 - acc: 0.5564 - val_loss: 2.3574 - val_acc: 0.3383\n",
      "Epoch 17/70\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.2312 - acc: 0.5625 - val_loss: 2.0122 - val_acc: 0.3296\n",
      "Epoch 18/70\n",
      "11200/50000 [=====>........................] - ETA: 14s - loss: 1.2141 - acc: 0.5666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-09becd528c59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# pmodel.save(save_path + 'keras_cifar10_example_pool_rmsprop_batchnorm.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "history = pmodel.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True, \n",
    "                    validation_data=(x_test, y_test))\n",
    "# pmodel.save(save_path + 'keras_cifar10_example_pool_rmsprop_batchnorm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(model):\n",
    "    \"\"\"\n",
    "    Get all coefficients of the convolutional kernels\n",
    "    \"\"\"\n",
    "    weights_list = []\n",
    "    biases_list = []\n",
    "    for layer in model.layers:\n",
    "        if layer.weights and 'kernel' in layer.weights[0].name:\n",
    "            w = layer.get_weights()[0].flatten()\n",
    "            b = layer.get_weights()[1].flatten()\n",
    "            weights_list.append(w)\n",
    "            biases_list.append(b)\n",
    "    \n",
    "    weights_arr = np.concatenate(weights_list)\n",
    "    biases_arr = np.concatenate(biases_list)\n",
    "\n",
    "    return weights_arr, biases_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = get_model_weights(pmodel)\n",
    "plt.hist(a, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
